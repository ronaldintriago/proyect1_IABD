import pandas as pd
import os
from src.config.db_config import DBConfig 

class DataLoader:
    
    REQUIRED_TABLES = ['Pedidos', 'LineasPedido', 'Productos', 'Clientes', 'Destinos']

    @staticmethod
    def load_manual_buffers(uploaded_files_dict):
        """
        Carga CSVs desde memoria.
        """
        print("üìÇ Leyendo archivos subidos por el usuario...")
        dfs = {}
        try:
            # 1. Leer lo que subi√≥ el usuario (Incluido Provincias.csv si est√°)
            for key, file_obj in uploaded_files_dict.items():
                if file_obj is not None:
                    file_obj.seek(0)
                    dfs[key] = pd.read_csv(file_obj, sep=',')
                    print(f"   ‚úÖ Le√≠do usuario: {key} ({len(dfs[key])} filas)")
            
            # 2. CARGA H√çBRIDA DE COORDENADAS
            # Siempre cargamos nuestro 'Provincias_geo.csv' interno como cach√© base.
            # feature.py se encargar√° de usarlo y, si falta algo, usar 'Provincias' del usuario.
            path_geo_interno = "data/raw/Provincias_geo.csv"
            if os.path.exists(path_geo_interno):
                print("   üåç Cargando cach√© de coordenadas interna (Provincias_geo.csv)...")
                dfs['Provincias_geo'] = pd.read_csv(path_geo_interno, sep=',')
            
            # Validaci√≥n
            if len(dfs) < len(DataLoader.REQUIRED_TABLES):
                faltan = set(DataLoader.REQUIRED_TABLES) - set(dfs.keys())
                print(f"‚ö†Ô∏è Faltan archivos obligatorios: {faltan}")
                return None
                
            return dfs
        except Exception as e:
            print(f"‚ùå Error leyendo buffers CSV: {e}")
            return None

    @staticmethod
    def load_from_csv(folder_path="data/raw"):
        # (Este m√©todo se mantiene igual que la √∫ltima versi√≥n funcional)
        print(f"üìÇ Cargando CSVs desde {folder_path}...")
        dfs = {}
        try:
            files = {
                'Pedidos': 'Pedidos.csv', 'LineasPedido': 'LineasPedido.csv',
                'Productos': 'Productos.csv', 'Clientes': 'Clientes.csv',
                'Destinos': 'Destinos.csv', 'Provincias_geo': 'Provincias_geo.csv',
                'Provincias': 'Provincias.csv' 
            }
            for key, filename in files.items():
                path = os.path.join(folder_path, filename)
                if os.path.exists(path):
                    dfs[key] = pd.read_csv(path, sep=',')
                elif key not in ['Provincias_geo', 'Provincias']: # Opcionales
                    raise FileNotFoundError(f"Falta: {filename}")
            return dfs
        except Exception as e:
            print(f"‚ùå Error: {e}")
            return None

    @staticmethod
    def load_from_sql():
        # (Este m√©todo se mantiene igual, con el fix de Destinos)
        print("üîå Conectando SQL...")
        dfs = {}
        try:
            engine = DBConfig.get_engine()
            for table in DataLoader.REQUIRED_TABLES:
                if table == 'Destinos':
                    query = "SELECT DestinoID, nombre_completo, distancia_km, provinciaID FROM Destinos"
                    dfs[table] = pd.read_sql(query, engine)
                else:
                    dfs[table] = pd.read_sql_table(table, engine)
            
            # Cargar geo interno siempre
            if os.path.exists("data/raw/Provincias_geo.csv"):
                dfs['Provincias_geo'] = pd.read_csv("data/raw/Provincias_geo.csv", sep=',')
            return dfs
        except Exception as e:
            print(f"‚ùå Error SQL: {e}")
            return None